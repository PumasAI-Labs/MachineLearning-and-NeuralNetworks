{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pumas-AI Introduction to Machine Learning and Neural Networks","text":"<p>This workshop provides an introduction to machine learning and neural networks in DeepPumas. Through a series of examples and exercises, it showcases the DeepPumas functionality and syntax for machine learning and neural networks, and introduces fundamental concepts and Generalization. </p> <p>Prerequisites</p> <p>The workshop is targeted to users familiar with statistical modeling and pharmacometrics who want to take advantage of DeepPumas to augment their models with machine learning components. Previous experience in machine learning is helpful but not required. We recommend users being familiar with the Pumas ecosystem and workflows, as covered in the NLME Modeling Workshop and its pre-requisites.</p>"},{"location":"#schedule","title":"Schedule","text":"Time (HH:MM) Activity Description 00:00 Setup Download files required for the workshop 00:05 A simple machine learning model Work on <code>1-linear_regression.jl</code> 00:10 Capturing complex relationships Work on <code>2-complex-relationships.jl</code> 00:20 Bias-variance tradeoff Work on <code>3-bias-variance_tradeoff.jl</code> 00:35 Generalization Work on <code>4-generalization.jl</code> 00:50 Closing remarks Q&amp;A and feedback"},{"location":"#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Andreu Vall - andreu@pumas.ai</li> <li>Niklas Korsbo - niklas@pumas.ai</li> </ul>"},{"location":"#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"code_of_conduct/","title":"Code of Conduct for Pumas-AI Introduction to Machine Learning and Neural Networks","text":"<p>At Pumas-AI we are committed to creating a friendly and respectful place for learning, teaching and contributing. All participants in our events and communications are expected to show respect and courtesy to others. To make clear what is expected, everyone participating in Pumas-AI activities is required to conform to the Code of Conduct.</p> <p>Pumas-AI is dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. As such, we do not tolerate behaviour that is disrespectful to our instructors or learners or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, veteran status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level.</p>"},{"location":"code_of_conduct/#expected-behaviour","title":"Expected Behaviour","text":"<p>All participants in our events and communications are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all Pumas-AI events and platforms:</p> <ul> <li>Use welcoming and inclusive language</li> <li>Be respectful of different viewpoints and experiences</li> <li>Gracefully accept constructive criticism</li> <li>Focus on what is best for the community</li> <li>Show courtesy and respect towards other community members</li> </ul>"},{"location":"code_of_conduct/#unacceptable-behaviour","title":"Unacceptable Behaviour","text":"<p>Examples of unacceptable behaviour by participants at any Pumas-AI event/platform include:</p> <ul> <li>written or verbal comments which have the effect of excluding people on the basis of membership of any specific group</li> <li>causing someone to fear for their safety, such as through stalking, following, or intimidation</li> <li>violent threats or language directed against another person</li> <li>the display of sexual or violent images</li> <li>unwelcome sexual attention</li> <li>nonconsensual or unwelcome physical contact</li> <li>sustained disruption of talks, events or communications</li> <li>insults or put downs</li> <li>sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes</li> <li>excessive swearing</li> <li>incitement to violence, suicide, or self-harm</li> <li>continuing to initiate interaction (including photography or recording) with someone after being asked to stop</li> <li>publication of private communication without consent</li> </ul>"},{"location":"code_of_conduct/#consequences-of-unacceptable-behaviour","title":"Consequences of Unacceptable Behaviour","text":"<p>Participants who are asked to stop any inappropriate behaviour are expected to comply immediately. This applies to any Pumas-AI events and platforms, either online or in-person. If a participant engages in behaviour that violates this code of conduct, the organisers may warn the offender, ask them to leave the event or platform (without refund, if applicable), or engage with Pumas-AI representatives to investigate the Code of Conduct violation and impose appropriate sanctions.</p>"},{"location":"code_of_conduct/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"code_of_conduct/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 Internacional.</p> <p></p>"},{"location":"contribute/","title":"How to Contribute","text":"<p>If you want to contribute to this workshop, please open a pull request at <code>PumasAI-Labs/MachineLearning-and-NeuralNetworks</code>.</p> <p>By submitting a pull request, you are in accordance that your contribution will be licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p>Once your pull request is approved and merged, you'll be acknowledged as one of the authors in the workshop site and GitHub repository.</p>"},{"location":"instructors/","title":"Instructor's Note for Pumas-AI Introduction to Machine Learning and Neural Networks","text":"<p>Note</p> <p>The code included in the workshop is split into separated scripts just for the sake of clarity. Each script can only be executed after the previous ones have been executed.</p> <p>Note</p> <p>The examples and exercises included in the workshop are technically very simple. This is because they are not meant as ready-made recipes, but rather as a basic material with which fundamental concepts can be presented and discussed.</p>"},{"location":"instructors/#suggested-itinerary","title":"Suggested itinerary","text":""},{"location":"instructors/#a-simple-machine-learning-model","title":"A simple machine learning model","text":"<p><code>01-linear_regression.jl</code> can be thought as a warm-up. A trivial synthetic dataset of pairs of scalars, \\(\\{ (x_i, y_i) \\}_{i=1}^N\\), is generated by drawing \\(x_i\\) from a uniform distribution and computing \\(y_i = x_i + \\varepsilon_i\\), where \\(\\varepsilon_i\\) is normally distributed noise. The dataset is not quite interesting, but it provides a good chance to introduce the concepts of supervised learning, empirical risk minimization and to reflect on the fact that, in the wild, the modeler is mostly unaware of which patterns may underlie the data.</p> <p>This dataset is fitted with a linear regression model implemented in DeepPumas. The linear regression model can be seen as the most basic form of a multilayer perceptron and thus, the connection between vocabulary and approaches in statistical modeling and machine learning can be highlighted. More interestingly, the implementation and fit of a linear regression model introduce the DeepPumas-specific <code>preprocess</code>, <code>MLPDomain</code> and <code>fit</code>.</p>"},{"location":"instructors/#capturing-complex-relationships","title":"Capturing complex relationships","text":"<p><code>02-complex_relationships.jl</code> starts by generating a \"more complex\" dataset. The new dataset, given by the relationship \\(y_i = x_i ^ 2 + \\varepsilon_i\\), is also quite uninteresting, but taken together, both datasets provide a pretext to discuss the need to adequate model complexity with the actual complexity required for the task at hand (exercise 2.2).</p> <p>The DeepPumas <code>MLPDomain</code>, briefly presented earlier, is used to implement a multilayer perceptron with one hidden layer. The occasion should be used to inspect the syntax required to specify the number of layers, the number of units, and the activation functions in an <code>MLPDomain</code>, and to remind the users that these details can be recalled through <code>?MLPDomain</code>.</p>"},{"location":"instructors/#bias-variance-tradeoff","title":"Bias-variance tradeoff","text":"<p><code>03-bias-variance_tradeoff.jl</code> discusses the training (or fitting) of machine learning models and the bias-variance tradeoff. To showcase examples of so-called underfitted and overfitted models, two main aspects are investigated, namely for how many epochs (or iterations) a machine learning model is fitted, the complexity of the machine learning model, and the relationship between the two.</p> <p>Exercise 3.1 deals with the number of training epochs. It introduces the ability to pass options to the optimizer through <code>optim_options</code>, in particular <code>optim_options = (; iterations = NUM_ITERATIONS)</code>. It shows that, for a machine learning model of complexity reasonably suited to the task at hand, both too few and too many training epochs can be detrimental. Exercises 3.2 and 3.3 further bring the effect of model complexity into the mix.</p> <p>This section may be striking for some users, since, if a machine learning model had the right level of complexity, and it reached \"the right solution\", how could training it longer possibly harm? Can different neural networks lead to similarly good solutions? This is a good moment to discuss the basic paradigm in which neural networks operate, including overparameterization, universal approximation theorem, existence of many local minima (and most likely absence of a global one), importance of careful design and fitting, and ability to cast a modeling problem as an optimization one.</p>"},{"location":"instructors/#generalization","title":"Generalization","text":"<p><code>04-generalization.jl</code> elaborates on the ability of machine learning models to make accurate predictions on unseen data. The section starts by presenting the concept of withheld (or validation, or test) data, as well as its crucial role in training machine learning models. Then, a bias-variance figure is constructed. Time should be taken to inspect and explain the figure in detail, and to draw connections to the previous section.</p> <p>The concept of regularization is introduced, along with the DeepPumas syntax to add regularization to an <code>MLPDomain</code>. This is a good time to describe regularization approaches based on the addition of a penalization term to the loss function, but the existence of other approaches such as early stopping, data augmentation and dropout should be mentioned.</p> <p>If time allows, introduce the larger concept of model selection, maybe starting with the concepts of hyperparameter and hyperparemeter optimization. At this point of the workshop, good examples of hyperparameters are the learning rate of a gradient descent algorithm, the weight given to the regularization term in a loss function, or the number of layers and of units in a multilayer perceptron. The (arguably blurry) difference between model parameters and hyperparameters deserves attention. Finally, the DeepPumas <code>hyperopt</code> tool for programmatic hyperparameter tuning is demonstrated.</p>"},{"location":"instructors/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"instructors/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"reference/","title":"Reference Sheets for Pumas-AI Introduction to Machine Learning and Neural Networks","text":""},{"location":"reference/#key-points","title":"Key Points","text":"<ul> <li>DeepPumas augments Pumas models with neural networks</li> <li>This workshop focuses both on DeepPumas and on machine learning concepts</li> <li>Fundamental concepts of machine learning and neural networks<ul> <li>supervised learning</li> <li>empirical risk minimization </li> <li>multilayer perceptron </li> <li>bias-variance tradeoff</li> <li>training, underfitting, overfitting</li> <li>generalization</li> <li>regularization</li> <li>model selection</li> <li>hyperparameter optimization</li> </ul> </li> <li>DeepPumas basic functionalities to work with neural networks<ul> <li><code>preprocess</code></li> <li><code>MLPDomain</code></li> <li><code>fit</code></li> <li><code>optim_options</code></li> <li><code>hyperopt</code></li> </ul> </li> </ul>"},{"location":"reference/#summary-of-basic-commands","title":"Summary of Basic Commands","text":"Action Command Observations Get a supervised machine learning dataset ready for further use with DeepPumas <code>preprocess</code> Expects data as matrices <code>X</code>, <code>Y</code>, with samples stored as columns, and returns a <code>FitTarget</code> for further use with <code>fit</code> and <code>hyperopt</code> Construct a multilayer perceptron <code>MLPDomain</code> The constructor accepts parameters to specify the number of layers, the number of units in each layer, the activation functions, and the type of regularization Fit a multilayer perceptron to a preprocessed supervised machine learning dataset <code>fit</code> It can also fit other machine learning models Pass options to the optimizer <code>optim_options</code> A <code>NamedTuple</code> of options to be passed on to the optimizer. Here, we experiment with the number of iterations Automate fitting and hyperparameter tuning <code>hyperopt</code> Optimize the parameters and hyperparameters of a machine learning model, in particular, of a multilayer perceptron"},{"location":"reference/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"reference/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"waiver/","title":"Waiver of Liability for Pumas-AI Introduction to Machine Learning and Neural Networks","text":"<p>By using the content provided by Pumas-AI, you agree to the following:</p> <ol> <li>You acknowledge that Pumas-AI has provided you with access to certain content (the \"Content\"),    including but not limited to software, documentation, images, videos, and other materials.</li> <li>You understand and agree that the Content is provided \"as is,\" without warranty of any kind,    either express or implied, including but not limited to the implied warranties of merchantability    and fitness for a particular purpose.</li> <li>You acknowledge that Pumas-AI is not responsible for how you use the Content,    and that Pumas-AI shall not be liable for any damages arising from your use of the Content,    including but not limited to direct, indirect, incidental, special, consequential, or punitive damages,    whether in an action of contract, negligence, or other tortious action,    even if Pumas-AI has been advised of the possibility of such damages.</li> <li>You agree to indemnify, defend, and hold harmless Pumas-AI, its officers, directors, employees, agents,    and affiliates from and against any and all claims, damages, losses, liabilities,    and expenses (including reasonable attorneys' fees) arising from your use of the Content.</li> <li>You acknowledge that this Waiver of Liability is a legally binding agreement between you and Pumas-AI,    and that it governs your use of the Content.    If you do not agree to the terms of this Waiver of Liability, you must immediately cease using the Content.</li> </ol>"},{"location":"waiver/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"waiver/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"}]}